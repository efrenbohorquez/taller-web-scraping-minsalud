# MinSalud Web Scraper

Un sistema completo de web scraping **Ã©tico y legal** para extraer documentos de normatividad del sitio web del Ministerio de Salud de Colombia.

## ğŸš€ CaracterÃ­sticas

- âœ… **Crawling inteligente**: Extrae automÃ¡ticamente todos los links del sitio
- âœ… **Descarga paralela**: Descarga PDFs de manera eficiente
- âœ… **ExtracciÃ³n de texto**: Usa PDFMiner y OCR como respaldo
- âœ… **Base de datos**: Carga automÃ¡tica a MongoDB Atlas
- âœ… **Logging completo**: Seguimiento detallado de todo el proceso
- âœ… **Manejo de errores**: Robusto y resistente a fallos
- ğŸ›¡ï¸ **MÃ³dulo de Ã‰tica**: Cumplimiento con leyes colombianas (Ley 1273/2009, Ley 1581/2012)
- ğŸ”’ **Rate Limiting**: Control de tasa de peticiones (2s mÃ­nimo entre requests)
- ğŸ“‹ **AuditorÃ­a Completa**: Registro de todas las actividades para accountability
- âš–ï¸ **Respeto robots.txt**: VerificaciÃ³n automÃ¡tica antes de cada request

## ğŸ“‹ InstalaciÃ³n

### 1. Instalar dependencias bÃ¡sicas
```bash
pip install -r requirements.txt
```

### 2. Dependencias opcionales para OCR
```bash
# Para Windows
pip install pytesseract pdf2image Pillow

# Descargar e instalar Tesseract OCR
# https://github.com/UB-Mannheim/tesseract/wiki
```

### 3. Configurar MongoDB
Editar `config.py` con tu URI de MongoDB Atlas:
```python
MONGO_URI = "mongodb+srv://usuario:password@cluster0.mongodb.net/"
```

## ğŸ¯ Uso

### Ejecutar pipeline completo
```bash
python main.py
```

### Ejecutar solo partes especÃ­ficas
```bash
# Solo extraer links
python main.py --only-crawl

# Solo descargar PDFs
python main.py --only-download

# Solo extraer texto
python main.py --only-text

# Solo cargar a MongoDB
python main.py --only-mongo

# Verificar configuraciÃ³n
python main.py --config-check
```

### Prueba bÃ¡sica
```bash
python test_basic.py
```

## ï¿½ï¸ Cumplimiento Ã‰tico y Legal

Este proyecto incluye un **mÃ³dulo completo de Ã©tica** que garantiza el cumplimiento de las leyes colombianas:

### Leyes Cumplidas
- âœ… **Ley 1273/2009**: PrevenciÃ³n de delitos informÃ¡ticos
- âœ… **Ley 1581/2012**: ProtecciÃ³n de datos personales
- âœ… **Ley 1712/2014**: Acceso a informaciÃ³n pÃºblica
- âœ… **Decreto 1377/2013**: ReglamentaciÃ³n de datos

### Controles Implementados
- ğŸ”’ **Whitelist de dominios**: Solo `minsalud.gov.co` y `datos.gov.co`
- â±ï¸ **Rate limiting**: 2 segundos mÃ­nimo entre peticiones
- ğŸ¤– **robots.txt**: VerificaciÃ³n automÃ¡tica antes de cada request
- ğŸ” **DetecciÃ³n de datos personales**: Protege cÃ©dulas, emails, telÃ©fonos
- ğŸ“ **AuditorÃ­a completa**: Log de todas las actividades en `logs/ethical_audit.log`

### Ejecutar Tests Ã‰ticos
```bash
# Verificar cumplimiento legal
python test_ethical.py

# Ver reporte de cumplimiento
python -c "from ethical_compliance import print_compliance_report; print_compliance_report()"
```

### DocumentaciÃ³n Ã‰tica
- ğŸ“„ **POLITICAS_ETICA_LEGAL.md**: Marco legal completo
- ğŸ“ **CERTIFICACION_ETICA.md**: Resultados de tests y certificaciÃ³n
- ğŸ“‹ Ver tambiÃ©n: `ethical_compliance.py` para detalles tÃ©cnicos

## ï¿½ğŸ“ Estructura del proyecto

```
minsalud_scraper/
â”œâ”€â”€ main.py              # Script principal
â”œâ”€â”€ config.py            # Configuraciones
â”œâ”€â”€ requirements.txt     # Dependencias
â”œâ”€â”€ test_basic.py        # Pruebas bÃ¡sicas
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ pdfs/           # PDFs descargados
â”‚   â”œâ”€â”€ json_output/    # Textos extraÃ­dos (JSON)
â”‚   â””â”€â”€ Links_MinSalud.json  # Lista de links
â”œâ”€â”€ logs/               # Archivos de log
â””â”€â”€ src/
    â””â”€â”€ scraper.py      # CÃ³digo principal
```

## âš™ï¸ ConfiguraciÃ³n

El archivo `config.py` contiene todas las configuraciones:

- **URLs**: Sitio web objetivo
- **Rutas**: Directorios de almacenamiento  
- **MongoDB**: ConfiguraciÃ³n de base de datos
- **OCR**: ConfiguraciÃ³n de Tesseract
- **ParalelizaciÃ³n**: NÃºmero de workers

## ğŸ“Š Salida

### Archivos JSON individuales
Cada PDF procesado genera un archivo JSON con:
```json
{
    "file": "nombre_archivo.pdf",
    "timestamp": "2025-10-07T...",
    "text": "texto extraÃ­do...",
    "method": "PDFMINER|OCR",
    "size_bytes": 123456,
    "char_count": 5000
}
```

### Base de datos MongoDB
Los mismos datos se cargan automÃ¡ticamente a MongoDB Atlas.

## ğŸ”§ SoluciÃ³n de problemas

### Error de OCR
```bash
# Instalar Tesseract en Windows
choco install tesseract

# O descargar desde:
# https://github.com/UB-Mannheim/tesseract/wiki
```

### Error de MongoDB
- Verificar URI de conexiÃ³n
- Comprobar conectividad de red
- Validar credenciales

### Errores de red
- El script incluye reintentos automÃ¡ticos
- Ajustar `REQUEST_TIMEOUT` en config.py

## ğŸ“ˆ Rendimiento

- **Descarga paralela**: Hasta 5 PDFs simultÃ¡neos
- **ExtracciÃ³n inteligente**: PDFMiner primero, OCR como respaldo
- **Manejo de memoria**: Procesamiento por chunks
- **Logging eficiente**: RotaciÃ³n automÃ¡tica de logs

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crear rama para feature
3. Commit cambios
4. Push a la rama
5. Abrir Pull Request

## ğŸ“„ Licencia

Este proyecto es de cÃ³digo abierto bajo licencia MIT.

---
**Desarrollado para el Taller de Big Data y Web Scraping** ğŸš€